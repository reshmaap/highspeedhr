{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a2728cea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import spacy\n",
    "import pymysql\n",
    "\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "import pickle\n",
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "421b588d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MySQL Database connection\n",
    "\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "# Creating engine which connect to MySQL\n",
    "user = 'root' # user name\n",
    "pw = 'Root123456' # password\n",
    "db = 'hispeedhr' # database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cca117a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating engine to connect database\n",
    "engine = create_engine(f\"mysql+pymysql://{user}:{pw}@localhost/{db}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2d45c4db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading data from database\n",
    "job_description_sql = 'select * from job_description_table'\n",
    "resume_sql = 'select * from resume_table'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "839d2e5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read job_description_df and resume_df using pd.read_sql_query\n",
    "job_description_df = pd.read_sql_query(job_description_sql, con=engine)\n",
    "resume_df = pd.read_sql_query(resume_sql, con=engine)\n",
    "\n",
    "# Select only the required columns\n",
    "job_description_df = job_description_df[[\"Category\", \"Job_desc_raw\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "16f53344",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 33 entries, 0 to 32\n",
      "Data columns (total 2 columns):\n",
      " #   Column    Non-Null Count  Dtype \n",
      "---  ------    --------------  ----- \n",
      " 0   Category  33 non-null     object\n",
      " 1   Resume    33 non-null     object\n",
      "dtypes: object(2)\n",
      "memory usage: 656.0+ bytes\n"
     ]
    }
   ],
   "source": [
    "resume_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e8f16350",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 84 entries, 0 to 83\n",
      "Data columns (total 2 columns):\n",
      " #   Column        Non-Null Count  Dtype \n",
      "---  ------        --------------  ----- \n",
      " 0   Category      84 non-null     object\n",
      " 1   Job_desc_raw  84 non-null     object\n",
      "dtypes: object(2)\n",
      "memory usage: 1.4+ KB\n"
     ]
    }
   ],
   "source": [
    "job_description_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f38c8897",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define functions for data processing\n",
    "\n",
    "def cleanRawText(rawText):\n",
    "    rawText = str(rawText)\n",
    "    rawText = re.sub('http\\S+\\s*', ' ', rawText)\n",
    "    rawText = re.sub('RT|cc', ' ', rawText)\n",
    "    rawText = re.sub('#\\S+', '', rawText)\n",
    "    rawText = re.sub('@\\S+', '  ', rawText)\n",
    "    rawText = re.sub('[%s]' % re.escape(\"\"\"!\"#$%&'()*+,-./:;<=>?@[\\]^_`{|}~\"\"\"), ' ', rawText)\n",
    "    rawText = re.sub(r'[^\\x00-\\x7f]', r' ', rawText) \n",
    "    rawText = re.sub('\\s+', ' ', rawText)\n",
    "    rawText = re.sub('Job Description', '', rawText)\n",
    "    return rawText\n",
    "\n",
    "def remove_stop_words(text):\n",
    "    if isinstance(text, str):\n",
    "        doc = nlp(text)\n",
    "        filtered_text = ' '.join([token.text for token in doc if not token.is_stop])\n",
    "        return filtered_text\n",
    "    else:\n",
    "        return ''\n",
    "\n",
    "def extract_entities(text):\n",
    "    doc = nlp(text)\n",
    "    named_entities = list(set([ent.text for ent in doc.ents]))\n",
    "    return named_entities\n",
    "\n",
    "def remove_words(text, words):\n",
    "    pattern = r'\\b(?:{})\\b'.format('|'.join(map(re.escape, words)))\n",
    "    return re.sub(pattern, '', text)\n",
    "\n",
    "def cleanResumeData(df):\n",
    "    df[\"Resume\"] = df[\"Resume\"].apply(lambda x: x.strip())\n",
    "    cleaned_resume = df[\"Resume\"].apply(cleanRawText)\n",
    "    df[\"cleaned_text\"] = cleaned_resume\n",
    "    return df\n",
    "\n",
    "def cleanJDData(df):\n",
    "    df[\"Job_desc_raw\"] = df[\"Job_desc_raw\"].apply(lambda x: x.strip())\n",
    "    cleaned_jd = df[\"Job_desc_raw\"].apply(cleanRawText)\n",
    "    df[\"cleaned_text\"] = cleaned_jd\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "98ba5d61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the English language model in spaCy\n",
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "aa2a505a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean the resume and job description data\n",
    "resume_df = cleanResumeData(resume_df)\n",
    "job_description_df = cleanJDData(job_description_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7a680000",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 33 entries, 0 to 32\n",
      "Data columns (total 3 columns):\n",
      " #   Column        Non-Null Count  Dtype \n",
      "---  ------        --------------  ----- \n",
      " 0   Category      33 non-null     object\n",
      " 1   Resume        33 non-null     object\n",
      " 2   cleaned_text  33 non-null     object\n",
      "dtypes: object(3)\n",
      "memory usage: 920.0+ bytes\n"
     ]
    }
   ],
   "source": [
    "resume_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "16f0d544",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 84 entries, 0 to 83\n",
      "Data columns (total 3 columns):\n",
      " #   Column        Non-Null Count  Dtype \n",
      "---  ------        --------------  ----- \n",
      " 0   Category      84 non-null     object\n",
      " 1   Job_desc_raw  84 non-null     object\n",
      " 2   cleaned_text  84 non-null     object\n",
      "dtypes: object(3)\n",
      "memory usage: 2.1+ KB\n"
     ]
    }
   ],
   "source": [
    "job_description_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ce0c3eb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the remove_stop_words function to each value in the 'cleaned_text' column\n",
    "job_description_df['cleaned_text_no_stopwords'] = job_description_df['cleaned_text'].apply(remove_stop_words)\n",
    "resume_df['cleaned_text_no_stopwords'] = resume_df['cleaned_text'].apply(remove_stop_words)\n",
    "\n",
    "# Apply the extract_entities function to each value in the 'cleaned_text' column\n",
    "job_description_df['named_entities'] = job_description_df['cleaned_text'].apply(extract_entities)\n",
    "resume_df['named_entities'] = resume_df['cleaned_text'].apply(extract_entities)\n",
    "\n",
    "# Apply the remove_words function to each row in the job_description_df and resume_df\n",
    "job_description_df['cleaned_text_no_ne'] = job_description_df.apply(lambda row: remove_words(row['cleaned_text'], row['named_entities']), axis=1)\n",
    "resume_df['cleaned_text_no_ne'] = resume_df.apply(lambda row: remove_words(row['cleaned_text'], row['named_entities']), axis=1)\n",
    "\n",
    "# Combine the resume and job description dataframes\n",
    "category_text_combined = pd.concat([resume_df[[\"Category\", \"cleaned_text_no_stopwords\"]],\n",
    "                                    job_description_df[[\"Category\", \"cleaned_text_no_stopwords\"]]], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8c8044e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 117 entries, 0 to 116\n",
      "Data columns (total 2 columns):\n",
      " #   Column                     Non-Null Count  Dtype \n",
      "---  ------                     --------------  ----- \n",
      " 0   Category                   117 non-null    object\n",
      " 1   cleaned_text_no_stopwords  117 non-null    object\n",
      "dtypes: object(2)\n",
      "memory usage: 2.0+ KB\n"
     ]
    }
   ],
   "source": [
    "category_text_combined.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "07af2cb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize and tag the text\n",
    "full_docs = [TaggedDocument(doc.split(' '), [i])\n",
    "             for i, doc in enumerate(category_text_combined.cleaned_text_no_stopwords)]\n",
    "\n",
    "# Instantiate the Doc2Vec model\n",
    "model = Doc2Vec(vector_size=32, window=2, min_count=1, workers=8, epochs=40)\n",
    "\n",
    "# Build the vocabulary and train the model\n",
    "model.build_vocab(full_docs)\n",
    "model.train(full_docs, total_examples=model.corpus_count, epochs=model.epochs)\n",
    "\n",
    "# Save the trained model using pickle\n",
    "with open('doc2vec_model.pkl', 'wb') as file:\n",
    "    pickle.dump(model, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cda674a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
