{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a2728cea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import spacy\n",
    "import pymysql\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "import pickle\n",
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a0a24137",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating engine which connect to MySQL\n",
    "user = 'root' # user name\n",
    "pw = 'Root123456' # password\n",
    "db = 'hispeedhr' # database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cca117a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating engine to connect database\n",
    "engine = create_engine(f\"mysql+pymysql://{user}:{pw}@localhost/{db}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2d45c4db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading data from database\n",
    "job_description_sql = 'select * from job_description_table'\n",
    "resume_sql = 'select * from resume_table'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "839d2e5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read job_description_df and resume_df using pd.read_sql_query\n",
    "job_description_df = pd.read_sql_query(job_description_sql, con=engine)\n",
    "resume_df = pd.read_sql_query(resume_sql, con=engine)\n",
    "\n",
    "# Select only the required columns\n",
    "job_description_df = job_description_df[[\"Category\", \"Job_desc_raw\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "98ba5d61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the English language model in spaCy\n",
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "49b642ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define functions for data processing\n",
    "\n",
    "def cleanRawText(rawText):\n",
    "    rawText = str(rawText)\n",
    "    rawText = re.sub('http\\S+\\s*', ' ', rawText)\n",
    "    rawText = re.sub('RT|cc', ' ', rawText)\n",
    "    rawText = re.sub('#\\S+', '', rawText)\n",
    "    rawText = re.sub('@\\S+', '  ', rawText)\n",
    "    rawText = re.sub('[%s]' % re.escape(\"\"\"!\"#$%&'()*+,-./:;<=>?@[\\]^_`{|}~\"\"\"), ' ', rawText)\n",
    "    rawText = re.sub(r'[^\\x00-\\x7f]', r' ', rawText) \n",
    "    rawText = re.sub('\\s+', ' ', rawText)\n",
    "    rawText = re.sub('Job Description', '', rawText)\n",
    "    return rawText\n",
    "\n",
    "def remove_stop_words(text):\n",
    "    if isinstance(text, str):\n",
    "        doc = nlp(text)\n",
    "        filtered_text = ' '.join([token.text for token in doc if not token.is_stop])\n",
    "        return filtered_text\n",
    "    else:\n",
    "        return ''\n",
    "\n",
    "def extract_entities(text):\n",
    "    doc = nlp(text)\n",
    "    named_entities = list(set([ent.text for ent in doc.ents]))\n",
    "    return named_entities\n",
    "\n",
    "def remove_words(text, words):\n",
    "    pattern = r'\\b(?:{})\\b'.format('|'.join(map(re.escape, words)))\n",
    "    return re.sub(pattern, '', text)\n",
    "\n",
    "def cleanResumeData(df):\n",
    "    df[\"Resume\"] = df[\"Resume\"].apply(lambda x: x.strip())\n",
    "    cleaned_resume = df[\"Resume\"].apply(cleanRawText)\n",
    "    df[\"cleaned_text\"] = cleaned_resume\n",
    "    return df\n",
    "\n",
    "def cleanJDData(df):\n",
    "    df[\"Job_desc_raw\"] = df[\"Job_desc_raw\"].apply(lambda x: x.strip())\n",
    "    cleaned_jd = df[\"Job_desc_raw\"].apply(cleanRawText)\n",
    "    df[\"cleaned_text\"] = cleaned_jd\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "aa2a505a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean the resume and job description data\n",
    "resume_df = cleanResumeData(resume_df)\n",
    "job_description_df = cleanJDData(job_description_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7a680000",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 33 entries, 0 to 32\n",
      "Data columns (total 3 columns):\n",
      " #   Column        Non-Null Count  Dtype \n",
      "---  ------        --------------  ----- \n",
      " 0   Category      33 non-null     object\n",
      " 1   Resume        33 non-null     object\n",
      " 2   cleaned_text  33 non-null     object\n",
      "dtypes: object(3)\n",
      "memory usage: 920.0+ bytes\n"
     ]
    }
   ],
   "source": [
    "resume_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "16f0d544",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 82 entries, 0 to 81\n",
      "Data columns (total 3 columns):\n",
      " #   Column        Non-Null Count  Dtype \n",
      "---  ------        --------------  ----- \n",
      " 0   Category      82 non-null     object\n",
      " 1   Job_desc_raw  82 non-null     object\n",
      " 2   cleaned_text  82 non-null     object\n",
      "dtypes: object(3)\n",
      "memory usage: 2.0+ KB\n"
     ]
    }
   ],
   "source": [
    "job_description_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ce0c3eb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the remove_stop_words function to each value in the 'cleaned_text' column\n",
    "job_description_df['cleaned_text_no_stopwords'] = job_description_df['cleaned_text'].apply(remove_stop_words)\n",
    "resume_df['cleaned_text_no_stopwords'] = resume_df['cleaned_text'].apply(remove_stop_words)\n",
    "\n",
    "# Apply the extract_entities function to each value in the 'cleaned_text' column\n",
    "job_description_df['named_entities'] = job_description_df['cleaned_text'].apply(extract_entities)\n",
    "resume_df['named_entities'] = resume_df['cleaned_text'].apply(extract_entities)\n",
    "\n",
    "# Apply the remove_words function to each row in the job_description_df and resume_df\n",
    "job_description_df['cleaned_text_no_ne'] = job_description_df.apply(lambda row: remove_words(row['cleaned_text'], row['named_entities']), axis=1)\n",
    "resume_df['cleaned_text_no_ne'] = resume_df.apply(lambda row: remove_words(row['cleaned_text'], row['named_entities']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9cda674a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = pickle.load(open('doc2vec_model.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "85d96138",
   "metadata": {},
   "outputs": [],
   "source": [
    "#generate vectors\n",
    "resume_text2vec = [model.infer_vector((resume_df['cleaned_text_no_stopwords'][i].split(' '))) \n",
    "            for i in range(0,len(resume_df['cleaned_text_no_stopwords']))]\n",
    "job_description_text2vec = [model.infer_vector((job_description_df['cleaned_text_no_stopwords'][i].split(' '))) \n",
    "            for i in range(0,len(job_description_df['cleaned_text_no_stopwords']))]\n",
    "\n",
    "\n",
    "resume_text2vec_list = np.array(resume_text2vec).tolist()\n",
    "job_description_text2vec_list = np.array(job_description_text2vec).tolist()\n",
    "#set list to dataframe column\n",
    "resume_df['text_vec'] = resume_text2vec_list\n",
    "job_description_df['text_vec'] = job_description_text2vec_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dd984b66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate cosine similarity between vectors in resume_df and job_description_df\n",
    "similarity_scores = cosine_similarity(job_description_df['text_vec'].tolist(), resume_df['text_vec'].tolist())\n",
    "\n",
    "# Create a new column in jd_raw_data_df with reference to top 5 cosine similarity scores\n",
    "top_5_scores = similarity_scores.argsort()[:, -5:][:, ::-1]  # Get the indices of top 5 scores for each row\n",
    "\n",
    "# Create a new column to store the top 5 similarity scores\n",
    "job_description_df['top_5_similarity_scores'] = [[similarity_scores[row][index] for index in indices] for row, indices in enumerate(top_5_scores)]\n",
    "\n",
    "# Create a new column to store the corresponding row indices in resume_df\n",
    "job_description_df['top_5_resume_indices'] = [resume_df.index[index_list].tolist() for index_list in top_5_scores]\n",
    "\n",
    "# Create a new column to store the corresponding categories in resume_df\n",
    "job_description_df['top_5_resume_category'] = [resume_df[\"Category\"][index_list].tolist() for index_list in top_5_scores]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9d38bd73",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save Cosine Scores\n",
    "job_description_df.to_csv(r\"C:\\Users\\gouth\\OneDrive\\Desktop\\ISB\\FP1\\FP1 Files\\job_description_text_processed.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ec6a803b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save Resume Data\n",
    "resume_df.to_csv(r\"C:\\Users\\gouth\\OneDrive\\Desktop\\ISB\\FP1\\FP1 Files\\resume_processed.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2e9016fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 82 entries, 0 to 81\n",
      "Data columns (total 10 columns):\n",
      " #   Column                     Non-Null Count  Dtype \n",
      "---  ------                     --------------  ----- \n",
      " 0   Category                   82 non-null     object\n",
      " 1   Job_desc_raw               82 non-null     object\n",
      " 2   cleaned_text               82 non-null     object\n",
      " 3   cleaned_text_no_stopwords  82 non-null     object\n",
      " 4   named_entities             82 non-null     object\n",
      " 5   cleaned_text_no_ne         82 non-null     object\n",
      " 6   text_vec                   82 non-null     object\n",
      " 7   top_5_similarity_scores    82 non-null     object\n",
      " 8   top_5_resume_indices       82 non-null     object\n",
      " 9   top_5_resume_category      82 non-null     object\n",
      "dtypes: object(10)\n",
      "memory usage: 6.5+ KB\n"
     ]
    }
   ],
   "source": [
    "job_description_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6e6a0d67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Job_desc_raw</th>\n",
       "      <th>cleaned_text_no_stopwords</th>\n",
       "      <th>top_5_similarity_scores</th>\n",
       "      <th>top_5_resume_indices</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Job Description\\n\\nPerform deep dive analyses ...</td>\n",
       "      <td>Perform deep dive analyses key business tren...</td>\n",
       "      <td>[0.6791920036328934, 0.6696130681300158, 0.597...</td>\n",
       "      <td>[4, 1, 6, 14, 2]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Job Description\\nManage, architect, and analyz...</td>\n",
       "      <td>Manage architect analyze big data build data...</td>\n",
       "      <td>[0.7706055220438287, 0.6934078815017484, 0.684...</td>\n",
       "      <td>[6, 4, 1, 8, 2]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Job Description\\n. Requirements: Should have a...</td>\n",
       "      <td>Requirements Bachelor Masters degree Compute...</td>\n",
       "      <td>[0.831020351700983, 0.7563424936652987, 0.7279...</td>\n",
       "      <td>[4, 6, 8, 20, 5]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Job Description\\nData Science Analyst\\nExperie...</td>\n",
       "      <td>Data Science Analyst Experience 2 t 6 years ...</td>\n",
       "      <td>[0.6912497687104263, 0.6583470634822609, 0.606...</td>\n",
       "      <td>[4, 6, 1, 8, 2]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Job Description\\r\\n\\t\\t        From building e...</td>\n",
       "      <td>building entire infrastructures platforms so...</td>\n",
       "      <td>[0.6249578617086218, 0.6207000723508641, 0.552...</td>\n",
       "      <td>[1, 6, 4, 20, 15]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>Job Description\\r\\n\\t\\t        Key Accountabil...</td>\n",
       "      <td>Key ountabilities Design develop database ap...</td>\n",
       "      <td>[0.6688625498028964, 0.6428691681148695, 0.618...</td>\n",
       "      <td>[29, 11, 4, 23, 24]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>Job Description\\r\\n\\t\\t        Qualifications:...</td>\n",
       "      <td>Qualifications Bachelors Masters degree Comp...</td>\n",
       "      <td>[0.791991649933256, 0.6884669198825714, 0.6490...</td>\n",
       "      <td>[4, 20, 23, 17, 22]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>Job Description\\nProficiency in Backup and Rec...</td>\n",
       "      <td>Proficiency Backup Recovery Database Adminis...</td>\n",
       "      <td>[0.6974069000199905, 0.6860018536592977, 0.663...</td>\n",
       "      <td>[4, 31, 27, 28, 32]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>Job Description\\nDescription:\\n\\nResponsible f...</td>\n",
       "      <td>Description Responsible physical database ar...</td>\n",
       "      <td>[0.693722378559423, 0.67103912365, 0.648932440...</td>\n",
       "      <td>[29, 4, 23, 26, 21]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>Job Description\\r\\n\\t\\t        Purpose of the ...</td>\n",
       "      <td>Purpose job Requirements Management RM Engin...</td>\n",
       "      <td>[0.4566988281784872, 0.4557231242194156, 0.424...</td>\n",
       "      <td>[26, 0, 23, 21, 29]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>82 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         Job_desc_raw  \\\n",
       "0   Job Description\\n\\nPerform deep dive analyses ...   \n",
       "1   Job Description\\nManage, architect, and analyz...   \n",
       "2   Job Description\\n. Requirements: Should have a...   \n",
       "3   Job Description\\nData Science Analyst\\nExperie...   \n",
       "4   Job Description\\r\\n\\t\\t        From building e...   \n",
       "..                                                ...   \n",
       "77  Job Description\\r\\n\\t\\t        Key Accountabil...   \n",
       "78  Job Description\\r\\n\\t\\t        Qualifications:...   \n",
       "79  Job Description\\nProficiency in Backup and Rec...   \n",
       "80  Job Description\\nDescription:\\n\\nResponsible f...   \n",
       "81  Job Description\\r\\n\\t\\t        Purpose of the ...   \n",
       "\n",
       "                            cleaned_text_no_stopwords  \\\n",
       "0     Perform deep dive analyses key business tren...   \n",
       "1     Manage architect analyze big data build data...   \n",
       "2     Requirements Bachelor Masters degree Compute...   \n",
       "3     Data Science Analyst Experience 2 t 6 years ...   \n",
       "4     building entire infrastructures platforms so...   \n",
       "..                                                ...   \n",
       "77    Key ountabilities Design develop database ap...   \n",
       "78    Qualifications Bachelors Masters degree Comp...   \n",
       "79    Proficiency Backup Recovery Database Adminis...   \n",
       "80    Description Responsible physical database ar...   \n",
       "81    Purpose job Requirements Management RM Engin...   \n",
       "\n",
       "                              top_5_similarity_scores top_5_resume_indices  \n",
       "0   [0.6791920036328934, 0.6696130681300158, 0.597...     [4, 1, 6, 14, 2]  \n",
       "1   [0.7706055220438287, 0.6934078815017484, 0.684...      [6, 4, 1, 8, 2]  \n",
       "2   [0.831020351700983, 0.7563424936652987, 0.7279...     [4, 6, 8, 20, 5]  \n",
       "3   [0.6912497687104263, 0.6583470634822609, 0.606...      [4, 6, 1, 8, 2]  \n",
       "4   [0.6249578617086218, 0.6207000723508641, 0.552...    [1, 6, 4, 20, 15]  \n",
       "..                                                ...                  ...  \n",
       "77  [0.6688625498028964, 0.6428691681148695, 0.618...  [29, 11, 4, 23, 24]  \n",
       "78  [0.791991649933256, 0.6884669198825714, 0.6490...  [4, 20, 23, 17, 22]  \n",
       "79  [0.6974069000199905, 0.6860018536592977, 0.663...  [4, 31, 27, 28, 32]  \n",
       "80  [0.693722378559423, 0.67103912365, 0.648932440...  [29, 4, 23, 26, 21]  \n",
       "81  [0.4566988281784872, 0.4557231242194156, 0.424...  [26, 0, 23, 21, 29]  \n",
       "\n",
       "[82 rows x 4 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "job_description_df[[\"Job_desc_raw\",\"cleaned_text_no_stopwords\",\"top_5_similarity_scores\",\"top_5_resume_indices\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30c2d083",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
