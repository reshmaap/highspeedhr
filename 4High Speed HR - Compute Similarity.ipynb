{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a2728cea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import spacy\n",
    "import pymysql\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "import pickle\n",
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a0a24137",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating engine which connect to MySQL\n",
    "user = 'root' # user name\n",
    "pw = 'Root123456' # password\n",
    "db = 'hispeedhr' # database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cca117a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating engine to connect database\n",
    "engine = create_engine(f\"mysql+pymysql://{user}:{pw}@localhost/{db}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2d45c4db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading data from database\n",
    "job_description_sql = 'select * from job_description_table'\n",
    "resume_sql = 'select * from resume_table'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "839d2e5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read job_description_df and resume_df using pd.read_sql_query\n",
    "job_description_df = pd.read_sql_query(job_description_sql, con=engine)\n",
    "resume_df = pd.read_sql_query(resume_sql, con=engine)\n",
    "\n",
    "# Select only the required columns\n",
    "job_description_df = job_description_df[[\"Category\", \"Job_desc_raw\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "98ba5d61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the English language model in spaCy\n",
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "49b642ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define functions for data processing\n",
    "\n",
    "def cleanRawText(rawText):\n",
    "    rawText = str(rawText)\n",
    "    rawText = re.sub('http\\S+\\s*', ' ', rawText)\n",
    "    rawText = re.sub('RT|cc', ' ', rawText)\n",
    "    rawText = re.sub('#\\S+', '', rawText)\n",
    "    rawText = re.sub('@\\S+', '  ', rawText)\n",
    "    rawText = re.sub('[%s]' % re.escape(\"\"\"!\"#$%&'()*+,-./:;<=>?@[\\]^_`{|}~\"\"\"), ' ', rawText)\n",
    "    rawText = re.sub(r'[^\\x00-\\x7f]', r' ', rawText) \n",
    "    rawText = re.sub('\\s+', ' ', rawText)\n",
    "    rawText = re.sub('Job Description', '', rawText)\n",
    "    return rawText\n",
    "\n",
    "def remove_stop_words(text):\n",
    "    if isinstance(text, str):\n",
    "        doc = nlp(text)\n",
    "        filtered_text = ' '.join([token.text for token in doc if not token.is_stop])\n",
    "        return filtered_text\n",
    "    else:\n",
    "        return ''\n",
    "\n",
    "def extract_entities(text):\n",
    "    doc = nlp(text)\n",
    "    named_entities = list(set([ent.text for ent in doc.ents]))\n",
    "    return named_entities\n",
    "\n",
    "def remove_words(text, words):\n",
    "    pattern = r'\\b(?:{})\\b'.format('|'.join(map(re.escape, words)))\n",
    "    return re.sub(pattern, '', text)\n",
    "\n",
    "def cleanResumeData(df):\n",
    "    df[\"Resume\"] = df[\"Resume\"].apply(lambda x: x.strip())\n",
    "    cleaned_resume = df[\"Resume\"].apply(cleanRawText)\n",
    "    df[\"cleaned_text\"] = cleaned_resume\n",
    "    return df\n",
    "\n",
    "def cleanJDData(df):\n",
    "    df[\"Job_desc_raw\"] = df[\"Job_desc_raw\"].apply(lambda x: x.strip())\n",
    "    cleaned_jd = df[\"Job_desc_raw\"].apply(cleanRawText)\n",
    "    df[\"cleaned_text\"] = cleaned_jd\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "aa2a505a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean the resume and job description data\n",
    "resume_df = cleanResumeData(resume_df)\n",
    "job_description_df = cleanJDData(job_description_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7a680000",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 33 entries, 0 to 32\n",
      "Data columns (total 3 columns):\n",
      " #   Column        Non-Null Count  Dtype \n",
      "---  ------        --------------  ----- \n",
      " 0   Category      33 non-null     object\n",
      " 1   Resume        33 non-null     object\n",
      " 2   cleaned_text  33 non-null     object\n",
      "dtypes: object(3)\n",
      "memory usage: 920.0+ bytes\n"
     ]
    }
   ],
   "source": [
    "resume_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "16f0d544",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 84 entries, 0 to 83\n",
      "Data columns (total 3 columns):\n",
      " #   Column        Non-Null Count  Dtype \n",
      "---  ------        --------------  ----- \n",
      " 0   Category      84 non-null     object\n",
      " 1   Job_desc_raw  84 non-null     object\n",
      " 2   cleaned_text  84 non-null     object\n",
      "dtypes: object(3)\n",
      "memory usage: 2.1+ KB\n"
     ]
    }
   ],
   "source": [
    "job_description_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ce0c3eb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the remove_stop_words function to each value in the 'cleaned_text' column\n",
    "job_description_df['cleaned_text_no_stopwords'] = job_description_df['cleaned_text'].apply(remove_stop_words)\n",
    "resume_df['cleaned_text_no_stopwords'] = resume_df['cleaned_text'].apply(remove_stop_words)\n",
    "\n",
    "# Apply the extract_entities function to each value in the 'cleaned_text' column\n",
    "job_description_df['named_entities'] = job_description_df['cleaned_text'].apply(extract_entities)\n",
    "resume_df['named_entities'] = resume_df['cleaned_text'].apply(extract_entities)\n",
    "\n",
    "# Apply the remove_words function to each row in the job_description_df and resume_df\n",
    "job_description_df['cleaned_text_no_ne'] = job_description_df.apply(lambda row: remove_words(row['cleaned_text'], row['named_entities']), axis=1)\n",
    "resume_df['cleaned_text_no_ne'] = resume_df.apply(lambda row: remove_words(row['cleaned_text'], row['named_entities']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9cda674a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read the existing model\n",
    "model = pickle.load(open('doc2vec_model.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "85d96138",
   "metadata": {},
   "outputs": [],
   "source": [
    "#generate vectors\n",
    "resume_text2vec = [model.infer_vector((resume_df['cleaned_text_no_stopwords'][i].split(' '))) \n",
    "            for i in range(0,len(resume_df['cleaned_text_no_stopwords']))]\n",
    "job_description_text2vec = [model.infer_vector((job_description_df['cleaned_text_no_stopwords'][i].split(' '))) \n",
    "            for i in range(0,len(job_description_df['cleaned_text_no_stopwords']))]\n",
    "\n",
    "\n",
    "resume_text2vec_list = np.array(resume_text2vec).tolist()\n",
    "job_description_text2vec_list = np.array(job_description_text2vec).tolist()\n",
    "#set list to dataframe column\n",
    "resume_df['text_vec'] = resume_text2vec_list\n",
    "job_description_df['text_vec'] = job_description_text2vec_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dd984b66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate cosine similarity between vectors in resume_df and job_description_df\n",
    "similarity_scores = cosine_similarity(job_description_df['text_vec'].tolist(), resume_df['text_vec'].tolist())\n",
    "\n",
    "# Create a new column in jd_raw_data_df with reference to top 5 cosine similarity scores\n",
    "top_5_scores = similarity_scores.argsort()[:, -5:][:, ::-1]  # Get the indices of top 5 scores for each row\n",
    "\n",
    "# Create a new column to store the top 5 similarity scores\n",
    "job_description_df['top_5_similarity_scores'] = [[similarity_scores[row][index] for index in indices] for row, indices in enumerate(top_5_scores)]\n",
    "\n",
    "# Create a new column to store the corresponding row indices in resume_df\n",
    "job_description_df['top_5_resume_indices'] = [resume_df.index[index_list].tolist() for index_list in top_5_scores]\n",
    "\n",
    "# Create a new column to store the corresponding categories in resume_df\n",
    "job_description_df['top_5_resume_category'] = [resume_df[\"Category\"][index_list].tolist() for index_list in top_5_scores]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9d38bd73",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save Cosine Scores\n",
    "job_description_df.to_csv(r\"job_description_text_processed.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ec6a803b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save Resume Data\n",
    "resume_df.to_csv(r\"resume_processed.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2e9016fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 84 entries, 0 to 83\n",
      "Data columns (total 10 columns):\n",
      " #   Column                     Non-Null Count  Dtype \n",
      "---  ------                     --------------  ----- \n",
      " 0   Category                   84 non-null     object\n",
      " 1   Job_desc_raw               84 non-null     object\n",
      " 2   cleaned_text               84 non-null     object\n",
      " 3   cleaned_text_no_stopwords  84 non-null     object\n",
      " 4   named_entities             84 non-null     object\n",
      " 5   cleaned_text_no_ne         84 non-null     object\n",
      " 6   text_vec                   84 non-null     object\n",
      " 7   top_5_similarity_scores    84 non-null     object\n",
      " 8   top_5_resume_indices       84 non-null     object\n",
      " 9   top_5_resume_category      84 non-null     object\n",
      "dtypes: object(10)\n",
      "memory usage: 6.7+ KB\n"
     ]
    }
   ],
   "source": [
    "job_description_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6e6a0d67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Job_desc_raw</th>\n",
       "      <th>cleaned_text_no_stopwords</th>\n",
       "      <th>top_5_similarity_scores</th>\n",
       "      <th>top_5_resume_indices</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Job Description\\n\\nPerform deep dive analyses ...</td>\n",
       "      <td>Perform deep dive analyses key business tren...</td>\n",
       "      <td>[0.698626629130113, 0.6122702799653892, 0.6106...</td>\n",
       "      <td>[1, 2, 14, 6, 25]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Job Description\\nManage, architect, and analyz...</td>\n",
       "      <td>Manage architect analyze big data build data...</td>\n",
       "      <td>[0.7549157835110617, 0.70567287017585, 0.64353...</td>\n",
       "      <td>[6, 1, 2, 8, 4]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Job Description\\nData Science Analyst\\nExperie...</td>\n",
       "      <td>Data Science Analyst Experience 2 t 6 years ...</td>\n",
       "      <td>[0.7342804874740243, 0.6903970439689374, 0.571...</td>\n",
       "      <td>[6, 1, 2, 0, 8]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Job Description\\r\\n\\t\\t        From building e...</td>\n",
       "      <td>building entire infrastructures platforms so...</td>\n",
       "      <td>[0.6571658859889116, 0.5983140812885066, 0.529...</td>\n",
       "      <td>[6, 1, 5, 8, 20]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Job Description\\r\\n\\t\\t        From building e...</td>\n",
       "      <td>building entire infrastructures platforms so...</td>\n",
       "      <td>[0.6492806735912013, 0.60274462031725, 0.52690...</td>\n",
       "      <td>[6, 1, 5, 8, 20]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>Job Description\\r\\n\\t\\t        Key Accountabil...</td>\n",
       "      <td>Key ountabilities Design develop database ap...</td>\n",
       "      <td>[0.6277244293090876, 0.6148292233640253, 0.600...</td>\n",
       "      <td>[29, 11, 23, 24, 18]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>Job Description\\r\\n\\t\\t        Qualifications:...</td>\n",
       "      <td>Qualifications Bachelors Masters degree Comp...</td>\n",
       "      <td>[0.7809483340725354, 0.6502631782484231, 0.627...</td>\n",
       "      <td>[4, 20, 24, 17, 5]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>Job Description\\nProficiency in Backup and Rec...</td>\n",
       "      <td>Proficiency Backup Recovery Database Adminis...</td>\n",
       "      <td>[0.6592041270343079, 0.6070742199940865, 0.602...</td>\n",
       "      <td>[4, 25, 31, 28, 27]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>Job Description\\nDescription:\\n\\nResponsible f...</td>\n",
       "      <td>Description Responsible physical database ar...</td>\n",
       "      <td>[0.6370916099876154, 0.632498175215042, 0.6214...</td>\n",
       "      <td>[26, 29, 23, 4, 25]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>Job Description\\r\\n\\t\\t        Troubleshoot an...</td>\n",
       "      <td>Troubleshoot fix Alteryx workflow issues dev...</td>\n",
       "      <td>[0.7074435192218328, 0.6880159100630676, 0.643...</td>\n",
       "      <td>[23, 24, 4, 29, 3]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>84 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         Job_desc_raw  \\\n",
       "0   Job Description\\n\\nPerform deep dive analyses ...   \n",
       "1   Job Description\\nManage, architect, and analyz...   \n",
       "2   Job Description\\nData Science Analyst\\nExperie...   \n",
       "3   Job Description\\r\\n\\t\\t        From building e...   \n",
       "4   Job Description\\r\\n\\t\\t        From building e...   \n",
       "..                                                ...   \n",
       "79  Job Description\\r\\n\\t\\t        Key Accountabil...   \n",
       "80  Job Description\\r\\n\\t\\t        Qualifications:...   \n",
       "81  Job Description\\nProficiency in Backup and Rec...   \n",
       "82  Job Description\\nDescription:\\n\\nResponsible f...   \n",
       "83  Job Description\\r\\n\\t\\t        Troubleshoot an...   \n",
       "\n",
       "                            cleaned_text_no_stopwords  \\\n",
       "0     Perform deep dive analyses key business tren...   \n",
       "1     Manage architect analyze big data build data...   \n",
       "2     Data Science Analyst Experience 2 t 6 years ...   \n",
       "3     building entire infrastructures platforms so...   \n",
       "4     building entire infrastructures platforms so...   \n",
       "..                                                ...   \n",
       "79    Key ountabilities Design develop database ap...   \n",
       "80    Qualifications Bachelors Masters degree Comp...   \n",
       "81    Proficiency Backup Recovery Database Adminis...   \n",
       "82    Description Responsible physical database ar...   \n",
       "83    Troubleshoot fix Alteryx workflow issues dev...   \n",
       "\n",
       "                              top_5_similarity_scores  top_5_resume_indices  \n",
       "0   [0.698626629130113, 0.6122702799653892, 0.6106...     [1, 2, 14, 6, 25]  \n",
       "1   [0.7549157835110617, 0.70567287017585, 0.64353...       [6, 1, 2, 8, 4]  \n",
       "2   [0.7342804874740243, 0.6903970439689374, 0.571...       [6, 1, 2, 0, 8]  \n",
       "3   [0.6571658859889116, 0.5983140812885066, 0.529...      [6, 1, 5, 8, 20]  \n",
       "4   [0.6492806735912013, 0.60274462031725, 0.52690...      [6, 1, 5, 8, 20]  \n",
       "..                                                ...                   ...  \n",
       "79  [0.6277244293090876, 0.6148292233640253, 0.600...  [29, 11, 23, 24, 18]  \n",
       "80  [0.7809483340725354, 0.6502631782484231, 0.627...    [4, 20, 24, 17, 5]  \n",
       "81  [0.6592041270343079, 0.6070742199940865, 0.602...   [4, 25, 31, 28, 27]  \n",
       "82  [0.6370916099876154, 0.632498175215042, 0.6214...   [26, 29, 23, 4, 25]  \n",
       "83  [0.7074435192218328, 0.6880159100630676, 0.643...    [23, 24, 4, 29, 3]  \n",
       "\n",
       "[84 rows x 4 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "job_description_df[[\"Job_desc_raw\",\"cleaned_text_no_stopwords\",\"top_5_similarity_scores\",\"top_5_resume_indices\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30c2d083",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
